# 3D Handpose Estimation using Single Depth Images (CSC490H5F)
**Group**: Gesture Geniuses

**Group Members**: Taha Kazi, Saad Afridi, Daria Illianova, Carlos Saputra

**Problem Statement**: Accurate and real-time estimation of 3D hand pose from single depth images is a pressing challenge in computer vision. Existing methods face limitations in precision and robustness, particularly in handling joint ambiguities, and complex hand poses. This project aims to utilize Machine Learning to improve the accuracy and reliability of 3D hand pose estimation, enhancing its applicability in virtual reality, gesture recognition, and human-computer interaction systems.

**Dataset**: We are working with the ICVL dataset in our project. The dataset is 2GB in size â€“ not as large as our previous chosen dataset, which is good for efficiency in processing and training. It contains a total of 5000 images with a 240x320 resolution for each image. Furthermore, there is labelled data available, where each image has 16 points in total. Each line of labelled data is corresponding to each hand, which is represented by the 16 joint locations in their 3D (x,y,z) position. [1] The order of 16 joints is Palm, Thumb root, Thumb mid, Thumb tip, Index root, Index mid, Index tip, Middle root, Middle mid, Middle tip, Ring root, Ring mid, Ring tip, Pinky root, Pinky mid, Pinky tip. [1] 

![image](https://github.com/CSC490-Capstone-Design-Course/machine-vision/assets/47696403/2e08181d-50d8-4555-9220-2b09c8ddad96)

A sample of hand images is available below, to get a visual sense of the ICVL dataset we used:

![image](https://github.com/CSC490-Capstone-Design-Course/machine-vision/assets/47696403/a3e62f5b-0e5e-4448-99ed-f38958216a44)

 https://labicvl.github.io/hand.html 

 **Implementation Overview**:

**Results**:

**Contributions**:

**References**:

[1] Imperical College of London. (n.d.). 3D articulated hand pose estimation with single depth images. 3D Hand Pose Estimation. https://labicvl.github.io/hand.html 
