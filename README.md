# machine-vision
**Group**: Gesture Geniuses

**Names**: Taha Kazi, Saad Afridi, Daria Illianova, Carlos Saputra

**Dataset**: We are using the ICVL Dataset, which includes 2965 frames of fully annotated hands interacting with different objects. https://labicvl.github.io/hand.html 

**Goal**: We want to estimate 3D pose of articulated human hands using single depth images only. 

**TODO**: We still need to work on Model Architecture & Design, Loss Function Design, Training Strategy and Evaluation Metrics.

